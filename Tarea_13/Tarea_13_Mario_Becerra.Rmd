---
title: "Tarea 13"
author: "Mario Becerra 124362"
date: "28/04/2015"
output: html_document
---

#Ejercicio 1

Comprimir una imagen en blanco y negro usando PCA.

```{r, cache=TRUE}
library(png)
tere <- readPNG('Image.png')
image(tere[,,1])
tereMat <- (tere[,,1]+tere[,,2]+tere[,,3])/3
dim(tereMat)

# svdTere <- svd(tereMat)
# 
# #Con SVD
# for(k in c(10,30,60,100)){
#   print(k)
#   image(svdTere$u[,1:k] %*% diag(svdTere$d)[1:k,1:k] %*% t(svdTere$v)[1:k,], axes = FALSE, col = grey(seq(0, 1, length = 256)))
# }

#Con PCA
calculaImagenReducida <- function(img, k) {
  Data_mean = apply(img, 2, mean) #Saca la media de cada columna
  a <- dim(img) #Dimensiones de la imagen original
  Data_meanNew <- rep(Data_mean, a[1])
  DataAdjust = img - Data_meanNew
  cov_data = cov(DataAdjust)
  eig <- eigen(cov_data)
  V_trans = t(eig$vectors)
  DataAdjust_trans = t(DataAdjust)
  FinalData = V_trans %*% DataAdjust_trans
  #PCs = a[2] - k
  Reduced_V = eig$vectors[,1:k]
  Y=t(Reduced_V) %*% DataAdjust_trans
  Compressed_Data=Reduced_V %*% Y                                         
  Compressed_Data = t(Compressed_Data) + Data_meanNew
  Compressed_Data
}

# for(i in c(2,10,30,50,100,300)){
#   print(i)
#   image(calculaImagenReducida(tereMat, i), axes = FALSE, col = grey(seq(0, 1, length = 256)))
# }

tati <- readPNG('Tat.png')
tatMean <- (tati[,,1]+tati[,,2]+tati[,,3])/3
dim(tatMean)
image(tatMean, axes = FALSE, col = grey(seq(0, 1, length = 256)), main='Original')
for(i in c(10,50,100,350, 500)){
  print(i)
  image(calculaImagenReducida(tatMean, i), , axes = FALSE, col = grey(seq(0, 1, length = 256)), main=paste(i, 'componentes'))
}
```

#Ejercicio 2

Implementa whitening en los datos faithful, compara las gráficas de los datos crudos y preprocesados.

Dats originales:
```{r}
library(knitr)
kable(head(faithful))
```

Media y matriz de covarianzas:
```{r}
sapply(faithful, mean)
cov(faithful)
```


```{r}
Cov <- cov(faithful)
eig2 <- eigen(Cov)
E <- eig2$vectors
D <- diag(eig2$values)
Dinv2 <- diag(1/sqrt(eig2$values))
faithfulcent <- faithful - cbind(rep(sapply(faithful, mean)[1], nrow(faithful)), rep(sapply(faithful, mean)[2], nrow(faithful)))
WhitenedFaithful <- t(Dinv2 %*% t(E) %*% t(faithfulcent))
```

Los datos con *whitening*:
```{r}
kable(as.data.frame(head(WhitenedFaithful)))
```

Media y matriz de covarianzas:

```{r}
apply(WhitenedFaithful, 2, mean)
cov(WhitenedFaithful)
```

```{r}
library(ggplot2)
ggplot(faithful) + geom_point(aes(x=eruptions, y=waiting)) + ggtitle('Originales')
ggplot(as.data.frame(WhitenedFaithful)) + geom_point(aes(x=V1, y=V2)) + ggtitle('Transformados')
```


#Ejercicio 3

3. Realiza un mapa de un estado, grafica alguna variable de tu interés (índice de marginación, población, ...) a nivel municipio coloreando los polígonos de acuerdo a esta variables. Si lo deseas utiliza como fondo una imagen de google maps.

```{r}
library(rgdal)
library(ggplot2)
library(dplyr)

pob <- read.csv('pobl.csv')
mun_shp <- readOGR("./municipios" , "MUNICIPIOS")
mun_shp@data$id = rownames(mun_shp@data)
DF_shp <- subset(mun_shp, CVE_ENT == '09')

DF_df <- DF_shp %>% 
  fortify(region = "CVE_MUN") %>%
  arrange(order)
DF_df$id <- as.integer(DF_df$id)

DF_ind <- DF_df %>%
  mutate(CVE = id) %>%
  left_join(pob[,c('id','pob')])

ggplot() + 
  geom_polygon(data = DF_ind, aes(long, lat, group = group, fill = pob)) +
  labs(title = "Población en el DF", fill = "Población") +
  coord_fixed()
```







